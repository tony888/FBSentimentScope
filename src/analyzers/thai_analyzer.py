"""
Thai sentiment analyzer implementation.

This module provides Thai language sentiment analysis using a lexicon-based
approach with Thai-specific sentiment words and phrases.
"""

from typing import List, Dict, Set
import re
import sys
import os

# Add src directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from analyzers.base_analyzer import SentimentAnalyzer
from core.models import SentimentScore, Language
from core.exceptions import SentimentAnalysisError


class ThaiSentimentAnalyzer(SentimentAnalyzer):
    """
    Lexicon-based sentiment analyzer for Thai text.
    
    Uses pre-defined lists of positive and negative Thai words,
    along with intensity modifiers and negation handling.
    """
    
    def __init__(self):
        """Initialize Thai sentiment analyzer with lexicons."""
        self.positive_words = self._load_positive_words()
        self.negative_words = self._load_negative_words()
        self.intensity_modifiers = self._load_intensity_modifiers()
        self.negation_words = self._load_negation_words()
        self.emoji_sentiment = self._load_emoji_sentiment()
    
    def _load_positive_words(self) -> Set[str]:
        """Load positive Thai words."""
        return {
            # Basic positive words
            'à¸”à¸µ', 'à¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¸¢à¸­à¸”à¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¹€à¸¥à¸´à¸¨', 'à¸”à¸µà¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¸ªà¸¸à¸”à¸¢à¸­à¸”', 'à¹€à¸ˆà¹‹à¸‡',
            'à¹€à¸à¹ˆà¸‡', 'à¹€à¸”à¹‡à¸”', 'à¸›à¸±à¸‡', 'à¹€à¸à¹‹', 'à¸§à¸´à¹€à¸¨à¸©', 'à¸™à¹ˆà¸²à¸—à¸¶à¹ˆà¸‡', 'à¹‚à¸”à¸”à¹€à¸”à¹ˆà¸™',
            
            # Emotional positive words
            'à¸£à¸±à¸', 'à¸Šà¸­à¸š', 'à¸«à¸¥à¸‡à¸£à¸±à¸', 'à¸›à¸£à¸°à¸—à¸±à¸šà¹ƒà¸ˆ', 'à¸Šà¸·à¹ˆà¸™à¸Šà¸¡', 'à¸Šà¸·à¹ˆà¸™à¹ƒà¸ˆ', 'à¸”à¸µà¹ƒà¸ˆ',
            'à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸¸à¸‚', 'à¸ªà¸¸à¸‚', 'à¸ªà¸™à¸¸à¸', 'à¹€à¸žà¸¥à¸´à¸”à¹€à¸žà¸¥à¸´à¸™', 'à¸ªà¸šà¸²à¸¢à¹ƒà¸ˆ', 'à¸­à¸šà¸­à¸¸à¹ˆà¸™',
            
            # Beauty and aesthetics
            'à¸ªà¸§à¸¢', 'à¸‡à¸²à¸¡', 'à¸™à¹ˆà¸²à¸£à¸±à¸', 'à¹€à¸ªà¸™à¹ˆà¸«à¹Œ', 'à¸¡à¸µà¹€à¸ªà¸™à¹ˆà¸«à¹Œ', 'à¸™à¹ˆà¸²à¸”à¸¹', 'à¸™à¹ˆà¸²à¸Šà¸¡',
            'à¸™à¹ˆà¸²à¸­à¸´à¸ˆà¸‰à¸²', 'à¸«à¸£à¸¹', 'à¸«à¸£à¸¹à¸«à¸£à¸²', 'à¸ªà¸‡à¹ˆà¸²', 'à¸ªà¸‡à¹ˆà¸²à¸‡à¸²à¸¡', 'à¹ƒà¸ª', 'à¹€à¸›à¸¥à¹ˆà¸‡à¸›à¸¥à¸±à¹ˆà¸‡',
            
            # Quality and performance
            'à¸„à¸¸à¸“à¸ à¸²à¸ž', 'à¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž', 'à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž', 'à¹„à¸”à¹‰à¸œà¸¥', 'à¹ƒà¸Šà¹‰à¹„à¸”à¹‰', 'à¸„à¸¸à¹‰à¸¡',
            'à¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²', 'à¹„à¸¡à¹ˆà¹à¸žà¸‡', 'à¸£à¸²à¸„à¸²à¸”à¸µ', 'à¸›à¸£à¸°à¸«à¸¢à¸±à¸”', 'à¸¡à¸²à¸•à¸£à¸à¸²à¸™', 'à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡',
            
            # Success and achievement
            'à¸ªà¸³à¹€à¸£à¹‡à¸ˆ', 'à¸Šà¸™à¸°', 'à¹„à¸”à¹‰', 'à¸šà¸£à¸£à¸¥à¸¸', 'à¸ªà¸¡à¸›à¸£à¸²à¸£à¸–à¸™à¸²', 'à¹€à¸®à¸‡', 'à¹‚à¸Šà¸„à¸”à¸µ',
            'à¸–à¸¹à¸à¹ƒà¸ˆ', 'à¸•à¸£à¸‡à¹ƒà¸ˆ', 'à¸¥à¸‡à¸•à¸±à¸§', 'à¹€à¸«à¸¡à¸²à¸°', 'à¸žà¸­à¹ƒà¸ˆ', 'à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡',
            
            # Intensity boosters
            'à¸¡à¸²à¸', 'à¸¡à¸²à¸à¹†', 'à¸ªà¸¸à¸”', 'à¸—à¸µà¹ˆà¸ªà¸¸à¸”', 'à¹€à¸«à¸¥à¸·à¸­à¹€à¸à¸´à¸™', 'à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸', 'à¹à¸ªà¸™',
            'à¹€à¸›à¹‡à¸™à¸—à¸µà¹ˆà¸ªà¸¸à¸”', 'à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸„à¸£à¹€à¸—à¸µà¸¢à¸š', 'à¹€à¸à¸´à¸™à¸„à¸²à¸”', 'à¹€à¸à¸´à¸™à¹„à¸›'
        }
    
    def _load_negative_words(self) -> Set[str]:
        """Load negative Thai words."""
        return {
            # Basic negative words
            'à¹à¸¢à¹ˆ', 'à¹€à¸¥à¸§', 'à¸«à¹ˆà¸§à¸¢', 'à¹€à¸ªà¸µà¸¢', 'à¸žà¸±à¸‡', 'à¹„à¸¡à¹ˆà¸”à¸µ', 'à¹„à¸¡à¹ˆà¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¹à¸£à¸‡',
            'à¸«à¸”à¸«à¸¹à¹ˆ', 'à¹€à¸¨à¸£à¹‰à¸²', 'à¸œà¸´à¸”à¸«à¸§à¸±à¸‡', 'à¸™à¹ˆà¸²à¹€à¸¨à¸£à¹‰à¸²', 'à¸™à¹ˆà¸²à¸ªà¸‡à¸ªà¤¾à¤°', 'à¸™à¹ˆà¸²à¹€à¸ªà¸µà¸¢à¸”à¸²à¸¢',
            
            # Emotional negative words
            'à¹€à¸à¸¥à¸µà¸¢à¸”', 'à¹€à¸šà¸·à¹ˆà¸­', 'à¸™à¹ˆà¸²à¹€à¸šà¸·à¹ˆà¸­', 'à¹‚à¸à¸£à¸˜', 'à¸«à¸‡à¸¸à¸”à¸«à¸‡à¸´à¸”', 'à¸£à¸³à¸„à¸²à¸',
            'à¸‰à¸¸à¸™à¹€à¸‰à¸µà¸¢à¸§', 'à¸§à¹‰à¸²à¸§à¸¸à¹ˆà¸™', 'à¸§à¸¸à¹ˆà¸™à¸§à¸²à¸¢', 'à¸à¸±à¸‡à¸§à¸¥', 'à¹€à¸„à¸£à¸µà¸¢à¸”', 'à¸•à¸·à¹ˆà¸™à¹€à¸•à¹‰à¸™',
            
            # Quality issues
            'à¸«à¹ˆà¸§à¸¢', 'à¹à¸¢à¹ˆ', 'à¹€à¸¥à¸§', 'à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸ž', 'à¹„à¸¡à¹ˆà¸”à¸µ', 'à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰à¹„à¸”à¹‰',
            'à¹€à¸ªà¸µà¸¢à¹€à¸‡à¸´à¸™', 'à¹à¸žà¸‡', 'à¹„à¸¡à¹ˆà¸„à¸¸à¹‰à¸¡', 'à¹„à¸¡à¹ˆà¸„à¸¸à¹‰à¸¡à¸„à¹ˆà¸²', 'à¹€à¸ªà¸µà¸¢à¸‚à¸­à¸‡', 'à¹€à¸ªà¸µà¸¢à¹€à¸§à¸¥à¸²',
            
            # Problems and failures
            'à¸œà¸´à¸”', 'à¸œà¸´à¸”à¸žà¸¥à¸²à¸”', 'à¸žà¸¥à¸²à¸”', 'à¸¥à¹‰à¸¡à¹€à¸«à¸¥à¸§', 'à¹€à¸ªà¸µà¸¢à¸«à¸²à¸¢', 'à¹€à¸ªà¸µà¸¢à¹ƒà¸ˆ',
            'à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ', 'à¹„à¸¡à¹ˆà¹„à¸”à¹‰', 'à¹„à¸¡à¹ˆà¸–à¸¹à¸', 'à¸›à¸±à¸à¸«à¸²', 'à¸¢à¸¸à¹ˆà¸‡à¸¢à¸²à¸', 'à¸¥à¸³à¸šà¸²à¸',
            
            # Physical discomfort
            'à¸›à¹ˆà¸§à¸¢', 'à¹„à¸¡à¹ˆà¸ªà¸šà¸²à¸¢', 'à¹€à¸ˆà¹‡à¸š', 'à¸›à¸§à¸”', 'à¹€à¸¡à¸·à¹ˆà¸­à¸¢', 'à¹€à¸«à¸™à¸·à¹ˆà¸­à¸¢', 'à¸­à¹ˆà¸­à¸™à¹€à¸žà¸¥à¸µà¸¢',
            'à¸•à¸²à¸¢', 'à¸«à¸²à¸¢', 'à¹€à¸ªà¸·à¹ˆà¸­à¸¡', 'à¹€à¸à¹ˆà¸²', 'à¸Šà¸³à¸£à¸¸à¸”', 'à¸‚à¸²à¸”', 'à¸«à¸±à¸', 'à¹à¸•à¸',
            
            # Intensity boosters for negative
            'à¸¡à¸²à¸', 'à¸¡à¸²à¸à¹†', 'à¸ªà¸¸à¸”', 'à¸—à¸µà¹ˆà¸ªà¸¸à¸”', 'à¹€à¸«à¸¥à¸·à¸­à¹€à¸à¸´à¸™', 'à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸',
            'à¹€à¸à¸´à¸™à¹„à¸›', 'à¹€à¸à¸´à¸™à¸„à¸²à¸”', 'à¹„à¸¡à¹ˆà¹„à¸«à¸§', 'à¸—à¸™à¹„à¸¡à¹ˆà¹„à¸«à¸§'
        }
    
    def _load_intensity_modifiers(self) -> Dict[str, float]:
        """Load intensity modifier words and their multipliers."""
        return {
            # Positive intensifiers
            'à¸¡à¸²à¸': 1.5, 'à¸¡à¸²à¸à¹†': 1.8, 'à¸ªà¸¸à¸”': 2.0, 'à¸—à¸µà¹ˆà¸ªà¸¸à¸”': 2.2,
            'à¹€à¸«à¸¥à¸·à¸­à¹€à¸à¸´à¸™': 1.8, 'à¸­à¸¢à¹ˆà¸²à¸‡à¸¡à¸²à¸': 1.6, 'à¹à¸ªà¸™': 1.7,
            'à¹€à¸›à¹‡à¸™à¸—à¸µà¹ˆà¸ªà¸¸à¸”': 2.0, 'à¹€à¸à¸´à¸™à¸„à¸²à¸”': 1.5, 'à¹€à¸à¸´à¸™à¹„à¸›': 1.4,
            
            # Negative intensifiers
            'à¹à¸¢à¹ˆà¸¡à¸²à¸': 1.5, 'à¸«à¹ˆà¸§à¸¢à¸¡à¸²à¸': 1.6, 'à¹€à¸¥à¸§à¸—à¸µà¹ˆà¸ªà¸¸à¸”': 2.0,
            'à¹„à¸¡à¹ˆà¹„à¸«à¸§': 1.4, 'à¸—à¸™à¹„à¸¡à¹ˆà¹„à¸«à¸§': 1.7,
            
            # Diminishers
            'à¸™à¸´à¸”à¸«à¸™à¹ˆà¸­à¸¢': 0.5, 'à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢': 0.6, 'à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡': 0.8,
            'à¸žà¸­': 0.7, 'à¸žà¸­à¹†': 0.6, 'à¸›à¸²à¸™à¸à¸¥à¸²à¸‡': 0.5
        }
    
    def _load_negation_words(self) -> Set[str]:
        """Load negation words that flip sentiment."""
        return {
            'à¹„à¸¡à¹ˆ', 'à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ', 'à¹„à¸¡à¹ˆà¹„à¸”à¹‰', 'à¹„à¸¡à¹ˆà¸¡à¸µ', 'à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™', 'à¹„à¸¡à¹ˆà¸„à¸§à¸£',
            'à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡', 'à¹„à¸¡à¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™', 'à¸«à¸¢à¸¸à¸”', 'à¹€à¸¥à¸´à¸', 'à¸«à¹‰à¸²à¸¡', 'à¹„à¸¡à¹ˆà¸­à¸¢à¸²à¸'
        }
    
    def _load_emoji_sentiment(self) -> Dict[str, float]:
        """Load emoji sentiment mappings."""
        return {
            # Positive emojis
            'ðŸ˜Š': 0.5, 'ðŸ˜ƒ': 0.6, 'ðŸ˜„': 0.7, 'ðŸ˜': 0.6, 'ðŸ˜†': 0.5,
            'ðŸ˜': 0.8, 'ðŸ¥°': 0.8, 'ðŸ˜˜': 0.7, 'ðŸ˜—': 0.5, 'ðŸ˜™': 0.5,
            'ðŸ˜š': 0.5, 'ðŸ¤—': 0.6, 'ðŸ¤©': 0.8, 'ðŸ˜Ž': 0.6, 'ðŸ˜‹': 0.5,
            'ðŸ‘': 0.5, 'ðŸ‘': 0.6, 'ðŸŽ‰': 0.7, 'âœ¨': 0.5, 'ðŸ’•': 0.8,
            'â¤ï¸': 0.9, 'ðŸ’–': 0.8, 'ðŸ’': 0.7, 'ðŸ”¥': 0.6, 'â­': 0.5,
            
            # Negative emojis
            'ðŸ˜¢': -0.6, 'ðŸ˜­': -0.8, 'ðŸ˜ž': -0.5, 'ðŸ˜”': -0.4, 'ðŸ˜Ÿ': -0.4,
            'ðŸ˜•': -0.3, 'ðŸ™': -0.3, 'ðŸ˜£': -0.5, 'ðŸ˜–': -0.6, 'ðŸ˜«': -0.7,
            'ðŸ˜©': -0.6, 'ðŸ˜¤': -0.5, 'ðŸ˜ ': -0.7, 'ðŸ˜¡': -0.8, 'ðŸ¤¬': -0.9,
            'ðŸ‘Ž': -0.5, 'ðŸ’”': -0.8, 'ðŸ˜µ': -0.6, 'ðŸ‘¹': -0.7, 'ðŸ’€': -0.8
        }
    
    def analyze(self, text: str) -> SentimentScore:
        """
        Analyze sentiment of Thai text.
        
        Args:
            text: Thai text to analyze for sentiment
            
        Returns:
            SentimentScore: Detailed sentiment analysis results
        """
        if not text or not text.strip():
            return SentimentScore(
                compound=0.0,
                positive=0.0,
                negative=0.0,
                neutral=1.0,
                confidence=1.0,
                analyzer_used=self.get_analyzer_name()
            )
        
        try:
            # Clean and tokenize text
            cleaned_text = self._preprocess_text(text)
            words = self._tokenize(cleaned_text)
            
            # Calculate sentiment scores
            positive_score = self._calculate_positive_score(words, text)
            negative_score = self._calculate_negative_score(words, text)
            emoji_score = self._calculate_emoji_score(text)
            
            # Combine scores
            total_positive = positive_score + max(0, emoji_score)
            total_negative = negative_score + max(0, -emoji_score)
            
            # Calculate compound score
            compound = self._calculate_compound_score(total_positive, total_negative, len(words))
            
            # Apply negation
            compound = self._apply_negation(compound, words)
            
            # Calculate component scores
            total_sentiment = total_positive + total_negative
            if total_sentiment > 0:
                positive = total_positive / total_sentiment
                negative = total_negative / total_sentiment
                neutral = max(0, 1 - positive - negative)
            else:
                positive = 0.0
                negative = 0.0
                neutral = 1.0
            
            # Calculate confidence
            confidence = min(1.0, abs(compound) + (total_sentiment / max(len(words), 1)) * 0.5)
            
            return SentimentScore(
                compound=max(-1.0, min(1.0, compound)),
                positive=positive,
                negative=negative,
                neutral=neutral,
                confidence=confidence,
                analyzer_used=self.get_analyzer_name()
            )
            
        except Exception as e:
            raise SentimentAnalysisError(f"Thai sentiment analysis failed: {e}")
    
    def _preprocess_text(self, text: str) -> str:
        """Preprocess Thai text for analysis."""
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text.strip())
        
        # Normalize some common variations
        text = text.replace('à¹†', '')  # Remove repetition marks for simplicity
        
        return text
    
    def _tokenize(self, text: str) -> List[str]:
        """Simple tokenization for Thai text."""
        # This is a simplified tokenization
        # In production, use pythainlp.tokenize.word_tokenize()
        words = []
        
        # Split by spaces first
        space_split = text.split()
        
        for segment in space_split:
            # Further split Thai text (simplified approach)
            current_word = ""
            for char in segment:
                if self._is_thai_char(char):
                    current_word += char
                else:
                    if current_word:
                        words.append(current_word)
                        current_word = ""
                    if char.strip():
                        words.append(char)
            
            if current_word:
                words.append(current_word)
        
        return [word for word in words if word.strip()]
    
    def _is_thai_char(self, char: str) -> bool:
        """Check if character is Thai."""
        return '\u0e00' <= char <= '\u0e7f'
    
    def _calculate_positive_score(self, words: List[str], full_text: str) -> float:
        """Calculate positive sentiment score."""
        score = 0.0
        
        for i, word in enumerate(words):
            if word in self.positive_words:
                base_score = 1.0
                
                # Apply intensity modifiers
                intensity = self._get_intensity_modifier(words, i)
                score += base_score * intensity
        
        # Check for positive phrases
        score += self._check_positive_phrases(full_text)
        
        return score
    
    def _calculate_negative_score(self, words: List[str], full_text: str) -> float:
        """Calculate negative sentiment score."""
        score = 0.0
        
        for i, word in enumerate(words):
            if word in self.negative_words:
                base_score = 1.0
                
                # Apply intensity modifiers
                intensity = self._get_intensity_modifier(words, i)
                score += base_score * intensity
        
        # Check for negative phrases
        score += self._check_negative_phrases(full_text)
        
        return score
    
    def _calculate_emoji_score(self, text: str) -> float:
        """Calculate sentiment score from emojis."""
        emoji_score = 0.0
        emoji_count = 0
        
        for char in text:
            if char in self.emoji_sentiment:
                emoji_score += self.emoji_sentiment[char]
                emoji_count += 1
        
        return emoji_score / max(emoji_count, 1) if emoji_count > 0 else 0.0
    
    def _get_intensity_modifier(self, words: List[str], word_index: int) -> float:
        """Get intensity modifier for a word based on surrounding context."""
        intensity = 1.0
        
        # Check previous words for intensifiers
        for i in range(max(0, word_index - 2), word_index):
            if words[i] in self.intensity_modifiers:
                intensity *= self.intensity_modifiers[words[i]]
        
        # Check following words for intensifiers
        for i in range(word_index + 1, min(len(words), word_index + 3)):
            if words[i] in self.intensity_modifiers:
                intensity *= self.intensity_modifiers[words[i]]
        
        return intensity
    
    def _calculate_compound_score(self, positive: float, negative: float, word_count: int) -> float:
        """Calculate compound sentiment score."""
        if word_count == 0:
            return 0.0
        
        # Normalize by word count
        normalized_positive = positive / word_count
        normalized_negative = negative / word_count
        
        # Calculate compound score
        compound = normalized_positive - normalized_negative
        
        # Apply sigmoid-like transformation to keep within reasonable bounds
        if compound > 0:
            compound = min(1.0, compound * 0.5)
        else:
            compound = max(-1.0, compound * 0.5)
        
        return compound
    
    def _apply_negation(self, compound: float, words: List[str]) -> float:
        """Apply negation logic to flip sentiment if needed."""
        negation_count = sum(1 for word in words if word in self.negation_words)
        
        # If odd number of negations, flip sentiment
        if negation_count % 2 == 1:
            compound = -compound
        
        return compound
    
    def _check_positive_phrases(self, text: str) -> float:
        """Check for positive phrase patterns."""
        positive_phrases = [
            'à¸”à¸µà¸¡à¸²à¸', 'à¹€à¸¢à¸µà¹ˆà¸¢à¸¡à¸¡à¸²à¸', 'à¸Šà¸­à¸šà¸¡à¸²à¸', 'à¸£à¸±à¸à¸¡à¸²à¸', 'à¸ªà¸§à¸¢à¸¡à¸²à¸',
            'à¸ªà¸¸à¸”à¸¢à¸­à¸”', 'à¸¢à¸­à¸”à¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¸”à¸µà¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¹€à¸ˆà¹‹à¸‡à¸¡à¸²à¸', 'à¹€à¸”à¹‡à¸”à¸¡à¸²à¸'
        ]
        
        score = 0.0
        for phrase in positive_phrases:
            if phrase in text:
                score += 0.5
        
        return score
    
    def _check_negative_phrases(self, text: str) -> float:
        """Check for negative phrase patterns."""
        negative_phrases = [
            'à¹à¸¢à¹ˆà¸¡à¸²à¸', 'à¸«à¹ˆà¸§à¸¢à¸¡à¸²à¸', 'à¹€à¸¥à¸§à¸¡à¸²à¸', 'à¹€à¸à¸¥à¸µà¸¢à¸”à¸¡à¸²à¸', 'à¹€à¸šà¸·à¹ˆà¸­à¸¡à¸²à¸',
            'à¹„à¸¡à¹ˆà¸”à¸µ', 'à¹„à¸¡à¹ˆà¸Šà¸­à¸š', 'à¹„à¸¡à¹ˆà¹€à¸¢à¸µà¹ˆà¸¢à¸¡', 'à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ', 'à¹„à¸¡à¹ˆà¸„à¸§à¸£'
        ]
        
        score = 0.0
        for phrase in negative_phrases:
            if phrase in text:
                score += 0.5
        
        return score
    
    def get_supported_languages(self) -> List[Language]:
        """
        Get languages supported by Thai analyzer.
        
        Returns:
            List[Language]: Supported languages (Thai and Mixed)
        """
        return [Language.THAI, Language.MIXED]
    
    def get_analyzer_name(self) -> str:
        """
        Get analyzer name.
        
        Returns:
            str: Analyzer name
        """
        return "thai_lexicon"
